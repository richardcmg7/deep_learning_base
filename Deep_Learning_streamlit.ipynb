{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/richardcmg7/deep_learning_base/blob/main/Deep_Learning_streamlit.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Ejemplo de uso de Modelo Preentrenado en Google Colab usando Python-StreamLite\n"
      ],
      "metadata": {
        "id": "3LQrlrI0MQ9g"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1. Probamos con un modelo que pueda dar solución al problema.  \n",
        "\n",
        "VGG 19 es un modelo de 19 capas entrenado con un dataset de mas de 1 millón de imagenes [ImageNet](http://www.image-net.org) "
      ],
      "metadata": {
        "id": "01k0JvRqMkb1"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WJ9hZtlmiAb2"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.applications.vgg19 import VGG19"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "FXZGX-LoMh1D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "classifier = VGG19(\n",
        "    include_top=True,\n",
        "    weights='imagenet',\n",
        "    input_tensor=None,\n",
        "    input_shape=None,\n",
        "    pooling=None,\n",
        "    classes=1000,\n",
        "    classifier_activation='softmax'\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MilFE-PHivl0",
        "outputId": "e93d651d-946a-4801-d7f8-a1ce822b66bb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg19/vgg19_weights_tf_dim_ordering_tf_kernels.h5\n",
            "574717952/574710816 [==============================] - 4s 0us/step\n",
            "574726144/574710816 [==============================] - 4s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2. Cargamos el modelo al formato adecuado. "
      ],
      "metadata": {
        "id": "sw3eqBS4Ne7H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "classifier.save(\"image_classification.hdf5\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vBNxDFl1jGFH",
        "outputId": "04fa4e24-6a46-4697-bb74-ed3eb05146e8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "classifier.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0o4T-vUTjZOe",
        "outputId": "279440da-9e85-4ba9-fc69-d2271972bdb9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"vgg19\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_1 (InputLayer)        [(None, 224, 224, 3)]     0         \n",
            "                                                                 \n",
            " block1_conv1 (Conv2D)       (None, 224, 224, 64)      1792      \n",
            "                                                                 \n",
            " block1_conv2 (Conv2D)       (None, 224, 224, 64)      36928     \n",
            "                                                                 \n",
            " block1_pool (MaxPooling2D)  (None, 112, 112, 64)      0         \n",
            "                                                                 \n",
            " block2_conv1 (Conv2D)       (None, 112, 112, 128)     73856     \n",
            "                                                                 \n",
            " block2_conv2 (Conv2D)       (None, 112, 112, 128)     147584    \n",
            "                                                                 \n",
            " block2_pool (MaxPooling2D)  (None, 56, 56, 128)       0         \n",
            "                                                                 \n",
            " block3_conv1 (Conv2D)       (None, 56, 56, 256)       295168    \n",
            "                                                                 \n",
            " block3_conv2 (Conv2D)       (None, 56, 56, 256)       590080    \n",
            "                                                                 \n",
            " block3_conv3 (Conv2D)       (None, 56, 56, 256)       590080    \n",
            "                                                                 \n",
            " block3_conv4 (Conv2D)       (None, 56, 56, 256)       590080    \n",
            "                                                                 \n",
            " block3_pool (MaxPooling2D)  (None, 28, 28, 256)       0         \n",
            "                                                                 \n",
            " block4_conv1 (Conv2D)       (None, 28, 28, 512)       1180160   \n",
            "                                                                 \n",
            " block4_conv2 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
            "                                                                 \n",
            " block4_conv3 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
            "                                                                 \n",
            " block4_conv4 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
            "                                                                 \n",
            " block4_pool (MaxPooling2D)  (None, 14, 14, 512)       0         \n",
            "                                                                 \n",
            " block5_conv1 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
            "                                                                 \n",
            " block5_conv2 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
            "                                                                 \n",
            " block5_conv3 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
            "                                                                 \n",
            " block5_conv4 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
            "                                                                 \n",
            " block5_pool (MaxPooling2D)  (None, 7, 7, 512)         0         \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 25088)             0         \n",
            "                                                                 \n",
            " fc1 (Dense)                 (None, 4096)              102764544 \n",
            "                                                                 \n",
            " fc2 (Dense)                 (None, 4096)              16781312  \n",
            "                                                                 \n",
            " predictions (Dense)         (None, 1000)              4097000   \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 143,667,240\n",
            "Trainable params: 143,667,240\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3. Habilitamos el framework para la aplicación"
      ],
      "metadata": {
        "id": "j39Db8-lN5DO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "dARKE9rxN3MN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q streamlit"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pq7CgxHikOB7",
        "outputId": "26045ad8-078b-4210-83e1-c1e17b7927aa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[K     |████████████████████████████████| 9.1 MB 10.3 MB/s \n",
            "\u001b[K     |████████████████████████████████| 78 kB 5.5 MB/s \n",
            "\u001b[K     |████████████████████████████████| 181 kB 56.2 MB/s \n",
            "\u001b[K     |████████████████████████████████| 4.7 MB 47.6 MB/s \n",
            "\u001b[K     |████████████████████████████████| 235 kB 36.9 MB/s \n",
            "\u001b[K     |████████████████████████████████| 164 kB 49.5 MB/s \n",
            "\u001b[K     |████████████████████████████████| 63 kB 904 kB/s \n",
            "\u001b[K     |████████████████████████████████| 51 kB 5.8 MB/s \n",
            "\u001b[?25h  Building wheel for validators (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4. Creamos la Aplicación utilizando Streamlit"
      ],
      "metadata": {
        "id": "j3OVOm_hOGvF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile app.py\n",
        "import streamlit as st\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.applications.imagenet_utils import preprocess_input, decode_predictions\n",
        "\n",
        "@st.cache(allow_output_mutation=True)\n",
        "def load_model():\n",
        "  model=tf.keras.models.load_model('/content/image_classification.hdf5')\n",
        "  return model\n",
        "with st.spinner('Model is being loaded..'):\n",
        "  model=load_model()\n",
        "\n",
        "st.write(\"\"\"\n",
        "         # Image Classification\n",
        "         \"\"\"\n",
        "         )\n",
        "\n",
        "file = st.file_uploader(\"Upload the image to be classified \\U0001F447\", type=[\"jpg\", \"png\"])\n",
        "import cv2\n",
        "from PIL import Image, ImageOps\n",
        "import numpy as np\n",
        "st.set_option('deprecation.showfileUploaderEncoding', False)\n",
        "def upload_predict(upload_image, model):\n",
        "    \n",
        "        size = (180,180)    \n",
        "        image = ImageOps.fit(upload_image, size, Image.ANTIALIAS)\n",
        "        image = np.asarray(image)\n",
        "        img = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "        img_resize = cv2.resize(img, dsize=(224, 224),interpolation=cv2.INTER_CUBIC)\n",
        "        \n",
        "        img_reshape = img_resize[np.newaxis,...]\n",
        "    \n",
        "        prediction = model.predict(img_reshape)\n",
        "        pred_class=decode_predictions(prediction,top=1)\n",
        "        \n",
        "        return pred_class\n",
        "if file is None:\n",
        "    st.text(\"Please upload an image file\")\n",
        "else:\n",
        "    image = Image.open(file)\n",
        "    st.image(image, use_column_width=True)\n",
        "    predictions = upload_predict(image, model)\n",
        "    image_class = str(predictions[0][0][1])\n",
        "    score=np.round(predictions[0][0][2],5) \n",
        "    st.write(\"The image is classified as\",image_class)\n",
        "    st.write(\"The similarity score is approximately\",score)\n",
        "    print(\"The image is classified as \",image_class, \"with a similarity score of\",score)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iwY3-uk9jpd4",
        "outputId": "04edd0e8-c904-4100-a036-b8bc533b2465"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing app.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 5. Lanzamos la aplicación y utilizamos localtunel para permitir el acceso externo. "
      ],
      "metadata": {
        "id": "x4Kj8ZeyOb-G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "! streamlit run app.py & npx localtunnel --port 8501"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ax0dox0Vp-1L",
        "outputId": "7c0335ff-0515-4c38-8c38-1a68abee581c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-09-15 15:37:32.049 INFO    numexpr.utils: NumExpr defaulting to 2 threads.\n",
            "\u001b[0m\n",
            "\u001b[34m\u001b[1m  You can now view your Streamlit app in your browser.\u001b[0m\n",
            "\u001b[0m\n",
            "\u001b[34m  Network URL: \u001b[0m\u001b[1mhttp://172.28.0.2:8501\u001b[0m\n",
            "\u001b[34m  External URL: \u001b[0m\u001b[1mhttp://35.247.82.148:8501\u001b[0m\n",
            "\u001b[0m\n",
            "\u001b[K\u001b[?25hnpx: installed 22 in 5.027s\n",
            "your url is: https://blue-tools-mate-35-247-82-148.loca.lt\n",
            "2022-09-15 15:38:27.335891: E tensorflow/stream_executor/cuda/cuda_driver.cc:271] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
            "2022-09-15 15:38:31.338 No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
            "Downloading data from https://storage.googleapis.com/download.tensorflow.org/data/imagenet_class_index.json\n",
            "40960/35363 [==================================] - 0s 0us/step\n",
            "49152/35363 [=========================================] - 0s 0us/step\n",
            "The image is classified as  seat_belt with a similarity score of 0.06913\n",
            "The image is classified as  crib with a similarity score of 0.77607\n",
            "The image is classified as  remote_control with a similarity score of 0.49956\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Fin del Ejemplo"
      ],
      "metadata": {
        "id": "e-zpNxz03vJj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Fin del Ejemplo\n"
      ],
      "metadata": {
        "id": "Rtm1bKKUOyUx"
      }
    }
  ]
}